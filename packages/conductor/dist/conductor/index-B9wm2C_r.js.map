{"version":3,"file":"index-B9wm2C_r.js","sources":["../../src/agents/built-in/rag/chunker.ts","../../src/agents/built-in/rag/rag-agent.ts"],"sourcesContent":["/**\n * Text Chunking Strategies\n *\n * Breaks down large text into smaller chunks for embedding\n */\n\nimport type { Chunk, ChunkStrategy } from './types.js'\n\nexport class Chunker {\n  /**\n   * Chunk text based on strategy\n   */\n  chunk(text: string, strategy: ChunkStrategy, chunkSize: number, overlap: number): Chunk[] {\n    switch (strategy) {\n      case 'fixed':\n        return this.fixedSizeChunking(text, chunkSize, overlap)\n      case 'semantic':\n        return this.semanticChunking(text, chunkSize, overlap)\n      case 'recursive':\n        return this.recursiveChunking(text, chunkSize, overlap)\n      default:\n        return this.fixedSizeChunking(text, chunkSize, overlap)\n    }\n  }\n\n  /**\n   * Fixed-size chunking with overlap\n   */\n  private fixedSizeChunking(text: string, chunkSize: number, overlap: number): Chunk[] {\n    const chunks: Chunk[] = []\n    const words = text.split(/\\s+/)\n\n    for (let i = 0; i < words.length; i += chunkSize - overlap) {\n      const chunkWords = words.slice(i, i + chunkSize)\n      const chunkText = chunkWords.join(' ')\n\n      chunks.push({\n        text: chunkText,\n        index: chunks.length,\n      })\n\n      // Stop if we've processed all words\n      if (i + chunkSize >= words.length) {\n        break\n      }\n    }\n\n    return chunks\n  }\n\n  /**\n   * Semantic chunking (breaks on paragraph boundaries)\n   */\n  private semanticChunking(text: string, chunkSize: number, overlap: number): Chunk[] {\n    const chunks: Chunk[] = []\n    const paragraphs = text.split(/\\n\\n+/)\n\n    let currentChunk: string[] = []\n    let currentSize = 0\n\n    for (const paragraph of paragraphs) {\n      const words = paragraph.split(/\\s+/)\n      const paragraphSize = words.length\n\n      // If adding this paragraph would exceed chunk size, save current chunk\n      if (currentSize + paragraphSize > chunkSize && currentChunk.length > 0) {\n        chunks.push({\n          text: currentChunk.join('\\n\\n'),\n          index: chunks.length,\n        })\n\n        // Start new chunk with overlap\n        if (overlap > 0 && currentChunk.length > 0) {\n          const lastParagraph = currentChunk[currentChunk.length - 1]\n          currentChunk = [lastParagraph, paragraph]\n          currentSize = lastParagraph.split(/\\s+/).length + paragraphSize\n        } else {\n          currentChunk = [paragraph]\n          currentSize = paragraphSize\n        }\n      } else {\n        currentChunk.push(paragraph)\n        currentSize += paragraphSize\n      }\n    }\n\n    // Add final chunk\n    if (currentChunk.length > 0) {\n      chunks.push({\n        text: currentChunk.join('\\n\\n'),\n        index: chunks.length,\n      })\n    }\n\n    return chunks\n  }\n\n  /**\n   * Recursive chunking (tries multiple separators)\n   */\n  private recursiveChunking(text: string, chunkSize: number, overlap: number): Chunk[] {\n    const separators = ['\\n\\n', '\\n', '. ', ' ']\n    return this.recursiveChunkingHelper(text, chunkSize, overlap, separators, 0)\n  }\n\n  private recursiveChunkingHelper(\n    text: string,\n    chunkSize: number,\n    overlap: number,\n    separators: string[],\n    depth: number\n  ): Chunk[] {\n    // Base case: if text is small enough, return it as a single chunk\n    const words = text.split(/\\s+/)\n    if (words.length <= chunkSize) {\n      return [{ text, index: 0 }]\n    }\n\n    // If we've run out of separators, fall back to fixed-size chunking\n    if (depth >= separators.length) {\n      return this.fixedSizeChunking(text, chunkSize, overlap)\n    }\n\n    const separator = separators[depth]\n    const parts = text.split(separator)\n\n    const chunks: Chunk[] = []\n    let currentChunk: string[] = []\n    let currentSize = 0\n\n    for (const part of parts) {\n      const partWords = part.split(/\\s+/)\n      const partSize = partWords.length\n\n      if (currentSize + partSize > chunkSize && currentChunk.length > 0) {\n        // Recursively chunk if still too large\n        const chunkText = currentChunk.join(separator)\n        const subChunks = this.recursiveChunkingHelper(\n          chunkText,\n          chunkSize,\n          overlap,\n          separators,\n          depth + 1\n        )\n        chunks.push(...subChunks.map((chunk, i) => ({ ...chunk, index: chunks.length + i })))\n\n        currentChunk = [part]\n        currentSize = partSize\n      } else {\n        currentChunk.push(part)\n        currentSize += partSize\n      }\n    }\n\n    // Process final chunk\n    if (currentChunk.length > 0) {\n      const chunkText = currentChunk.join(separator)\n      const subChunks = this.recursiveChunkingHelper(\n        chunkText,\n        chunkSize,\n        overlap,\n        separators,\n        depth + 1\n      )\n      chunks.push(...subChunks.map((chunk, i) => ({ ...chunk, index: chunks.length + i })))\n    }\n\n    return chunks\n  }\n}\n","/**\n * RAG Agent - Retrieval-Augmented Generation\n *\n * Uses Cloudflare Vectorize and AI embeddings for semantic search\n *\n * Operations:\n * - index: Store content in vector database\n * - search: Find relevant content using semantic search\n */\n\nimport { BaseAgent, type AgentExecutionContext } from '../../base-agent.js'\nimport type { AgentConfig } from '../../../runtime/parser.js'\nimport type {\n  RAGConfig,\n  RAGInput,\n  RAGIndexInput,\n  RAGSearchInput,\n  RAGResult,\n  RAGIndexResult,\n  RAGSearchResult,\n  RAGSearchResultItem,\n} from './types.js'\nimport { Chunker } from './chunker.js'\nimport type { ConductorEnv } from '../../../types/env.js'\nimport { createLogger } from '../../../observability/index.js'\n\nconst logger = createLogger({ serviceName: 'rag-agent' })\n\n/**\n * Embedding model response from Cloudflare AI\n */\ninterface EmbeddingResponse {\n  shape?: number[]\n  data?: number[][]\n  pooling?: 'mean' | 'cls'\n}\n\n/**\n * Reranker response from Cloudflare AI\n */\ninterface RerankerResponse {\n  response?: Array<{\n    id?: number\n    score?: number\n  }>\n}\n\nexport class RAGMember extends BaseAgent {\n  private ragConfig: RAGConfig\n  private chunker: Chunker\n\n  constructor(\n    config: AgentConfig,\n    private readonly env: ConductorEnv\n  ) {\n    super(config)\n\n    const cfg = config.config as RAGConfig | undefined\n\n    this.ragConfig = {\n      operation: cfg?.operation || 'search',\n      chunkStrategy: cfg?.chunkStrategy || 'semantic',\n      chunkSize: cfg?.chunkSize || 512,\n      overlap: cfg?.overlap || 50,\n      embeddingModel: cfg?.embeddingModel || '@cf/baai/bge-base-en-v1.5',\n      topK: cfg?.topK || 5,\n      rerank: cfg?.rerank || false,\n      rerankModel: cfg?.rerankModel || '@cf/baai/bge-reranker-base',\n      namespace: cfg?.namespace,\n    }\n\n    this.chunker = new Chunker()\n  }\n\n  protected async run(context: AgentExecutionContext): Promise<RAGResult> {\n    const input = context.input as RAGInput\n    const operation = this.ragConfig.operation!\n\n    switch (operation) {\n      case 'index':\n        return await this.indexContent(input as RAGIndexInput)\n      case 'search':\n        return await this.searchContent(input as RAGSearchInput)\n      default:\n        throw new Error(`Unknown RAG operation: ${operation}`)\n    }\n  }\n\n  /**\n   * Index content into vector database\n   */\n  private async indexContent(input: RAGIndexInput): Promise<RAGIndexResult> {\n    if (!input.content) {\n      throw new Error('Index operation requires \"content\" in input')\n    }\n\n    if (!input.id) {\n      throw new Error('Index operation requires \"id\" in input')\n    }\n\n    // Check required bindings\n    if (!this.env.AI) {\n      throw new Error('RAG agent requires AI binding. Add [ai] binding = \"AI\" to wrangler.toml')\n    }\n\n    if (!this.env.VECTORIZE) {\n      throw new Error(\n        'RAG agent requires VECTORIZE binding. Add [[vectorize]] binding = \"VECTORIZE\" to wrangler.toml'\n      )\n    }\n\n    // 1. Chunk content\n    const chunks = this.chunker.chunk(\n      input.content,\n      this.ragConfig.chunkStrategy!,\n      this.ragConfig.chunkSize!,\n      this.ragConfig.overlap!\n    )\n\n    logger.debug('Chunked content', { docId: input.id, chunkCount: chunks.length })\n\n    // 2. Generate embeddings using Cloudflare AI\n    const embeddings = await this.generateEmbeddings(chunks)\n\n    // 3. Store in Vectorize\n    await this.storeInVectorize(input.id, chunks, embeddings, input.metadata)\n\n    logger.info('Indexed document', {\n      docId: input.id,\n      chunks: chunks.length,\n      model: this.ragConfig.embeddingModel,\n    })\n\n    return {\n      indexed: chunks.length,\n      chunks: chunks.length,\n      embeddingModel: this.ragConfig.embeddingModel!,\n      chunkStrategy: this.ragConfig.chunkStrategy!,\n    }\n  }\n\n  /**\n   * Search content in vector database\n   */\n  private async searchContent(input: RAGSearchInput): Promise<RAGSearchResult> {\n    if (!input.query) {\n      throw new Error('Search operation requires \"query\" in input')\n    }\n\n    // Check required bindings\n    if (!this.env.AI) {\n      throw new Error('RAG agent requires AI binding. Add [ai] binding = \"AI\" to wrangler.toml')\n    }\n\n    if (!this.env.VECTORIZE) {\n      throw new Error(\n        'RAG agent requires VECTORIZE binding. Add [[vectorize]] binding = \"VECTORIZE\" to wrangler.toml'\n      )\n    }\n\n    // 1. Generate query embedding\n    const queryEmbedding = await this.generateEmbedding(input.query)\n\n    // 2. Search Vectorize\n    let results = await this.searchVectorize(\n      queryEmbedding,\n      input.filter,\n      input.topK ?? this.ragConfig.topK\n    )\n\n    // 3. Rerank if configured\n    const shouldRerank = input.rerank ?? this.ragConfig.rerank\n    if (shouldRerank && results.length > 0) {\n      results = await this.rerank(input.query, results)\n    }\n\n    logger.debug('Search completed', {\n      query: input.query.slice(0, 50),\n      resultCount: results.length,\n      reranked: shouldRerank,\n    })\n\n    return {\n      results,\n      count: results.length,\n      reranked: shouldRerank!,\n    }\n  }\n\n  /**\n   * Generate embeddings using Cloudflare AI\n   */\n  private async generateEmbeddings(chunks: Array<{ text: string }>): Promise<number[][]> {\n    const texts = chunks.map((c) => c.text)\n\n    // Cloudflare AI supports batching up to 100 texts\n    const batchSize = 100\n    const allEmbeddings: number[][] = []\n\n    for (let i = 0; i < texts.length; i += batchSize) {\n      const batch = texts.slice(i, i + batchSize)\n\n      const response = (await this.env.AI.run(this.ragConfig.embeddingModel!, {\n        text: batch,\n        pooling: 'cls', // Use CLS pooling for better accuracy on longer texts\n      })) as EmbeddingResponse\n\n      if (!response.data) {\n        throw new Error('Failed to generate embeddings: no data returned from AI')\n      }\n\n      allEmbeddings.push(...response.data)\n    }\n\n    return allEmbeddings\n  }\n\n  /**\n   * Generate a single embedding\n   */\n  private async generateEmbedding(text: string): Promise<number[]> {\n    const response = (await this.env.AI.run(this.ragConfig.embeddingModel!, {\n      text: [text],\n      pooling: 'cls',\n    })) as EmbeddingResponse\n\n    if (!response.data || response.data.length === 0) {\n      throw new Error('Failed to generate embedding: no data returned from AI')\n    }\n\n    return response.data[0]\n  }\n\n  /**\n   * Store chunks in Vectorize\n   */\n  private async storeInVectorize(\n    docId: string,\n    chunks: Array<{ text: string; index: number }>,\n    embeddings: number[][],\n    metadata?: Record<string, unknown>\n  ): Promise<void> {\n    const vectors = chunks.map((chunk, i) => ({\n      id: `${docId}-chunk-${chunk.index}`,\n      values: embeddings[i],\n      namespace: this.ragConfig.namespace,\n      metadata: {\n        content: chunk.text,\n        docId,\n        chunkIndex: chunk.index,\n        ...metadata,\n      },\n    }))\n\n    // Vectorize supports batching up to 1000 vectors\n    const batchSize = 1000\n    for (let i = 0; i < vectors.length; i += batchSize) {\n      const batch = vectors.slice(i, i + batchSize)\n      await this.env.VECTORIZE!.upsert(batch)\n    }\n  }\n\n  /**\n   * Search Vectorize for similar vectors\n   */\n  private async searchVectorize(\n    queryEmbedding: number[],\n    filter?: Record<string, unknown>,\n    topK?: number\n  ): Promise<RAGSearchResultItem[]> {\n    const results = await this.env.VECTORIZE!.query(queryEmbedding, {\n      topK: topK ?? this.ragConfig.topK!,\n      namespace: this.ragConfig.namespace,\n      filter: filter as VectorizeVectorMetadataFilter | undefined,\n      returnValues: false, // Don't need embeddings back\n      returnMetadata: 'all', // Get full metadata including content\n    })\n\n    // Transform Vectorize results to our format\n    return results.matches.map((match) => ({\n      id: match.id,\n      score: match.score,\n      content: (match.metadata?.content as string) || '',\n      metadata: match.metadata || {},\n    }))\n  }\n\n  /**\n   * Rerank search results using cross-encoder model\n   */\n  private async rerank(\n    query: string,\n    results: RAGSearchResultItem[]\n  ): Promise<RAGSearchResultItem[]> {\n    if (results.length === 0) {\n      return results\n    }\n\n    // Prepare contexts for reranker\n    const contexts = results.map((r) => ({\n      text: r.content,\n    }))\n\n    // Call the reranker model\n    const response = (await this.env.AI.run(this.ragConfig.rerankModel!, {\n      query,\n      contexts,\n      top_k: results.length, // Rerank all results\n    })) as RerankerResponse\n\n    if (!response.response || response.response.length === 0) {\n      logger.warn('Reranker returned no results, using original order')\n      return results\n    }\n\n    // Reorder results based on reranker scores\n    const rerankedResults: RAGSearchResultItem[] = []\n    for (const item of response.response) {\n      if (item.id !== undefined && item.score !== undefined) {\n        const originalResult = results[item.id]\n        if (originalResult) {\n          rerankedResults.push({\n            ...originalResult,\n            score: item.score, // Use reranker score\n          })\n        }\n      }\n    }\n\n    return rerankedResults\n  }\n}\n"],"names":[],"mappings":";AAQO,MAAM,QAAQ;AAAA;AAAA;AAAA;AAAA,EAInB,MAAM,MAAc,UAAyB,WAAmB,SAA0B;AACxF,YAAQ,UAAA;AAAA,MACN,KAAK;AACH,eAAO,KAAK,kBAAkB,MAAM,WAAW,OAAO;AAAA,MACxD,KAAK;AACH,eAAO,KAAK,iBAAiB,MAAM,WAAW,OAAO;AAAA,MACvD,KAAK;AACH,eAAO,KAAK,kBAAkB,MAAM,WAAW,OAAO;AAAA,MACxD;AACE,eAAO,KAAK,kBAAkB,MAAM,WAAW,OAAO;AAAA,IAAA;AAAA,EAE5D;AAAA;AAAA;AAAA;AAAA,EAKQ,kBAAkB,MAAc,WAAmB,SAA0B;AACnF,UAAM,SAAkB,CAAA;AACxB,UAAM,QAAQ,KAAK,MAAM,KAAK;AAE9B,aAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK,YAAY,SAAS;AAC1D,YAAM,aAAa,MAAM,MAAM,GAAG,IAAI,SAAS;AAC/C,YAAM,YAAY,WAAW,KAAK,GAAG;AAErC,aAAO,KAAK;AAAA,QACV,MAAM;AAAA,QACN,OAAO,OAAO;AAAA,MAAA,CACf;AAGD,UAAI,IAAI,aAAa,MAAM,QAAQ;AACjC;AAAA,MACF;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKQ,iBAAiB,MAAc,WAAmB,SAA0B;AAClF,UAAM,SAAkB,CAAA;AACxB,UAAM,aAAa,KAAK,MAAM,OAAO;AAErC,QAAI,eAAyB,CAAA;AAC7B,QAAI,cAAc;AAElB,eAAW,aAAa,YAAY;AAClC,YAAM,QAAQ,UAAU,MAAM,KAAK;AACnC,YAAM,gBAAgB,MAAM;AAG5B,UAAI,cAAc,gBAAgB,aAAa,aAAa,SAAS,GAAG;AACtE,eAAO,KAAK;AAAA,UACV,MAAM,aAAa,KAAK,MAAM;AAAA,UAC9B,OAAO,OAAO;AAAA,QAAA,CACf;AAGD,YAAI,UAAU,KAAK,aAAa,SAAS,GAAG;AAC1C,gBAAM,gBAAgB,aAAa,aAAa,SAAS,CAAC;AAC1D,yBAAe,CAAC,eAAe,SAAS;AACxC,wBAAc,cAAc,MAAM,KAAK,EAAE,SAAS;AAAA,QACpD,OAAO;AACL,yBAAe,CAAC,SAAS;AACzB,wBAAc;AAAA,QAChB;AAAA,MACF,OAAO;AACL,qBAAa,KAAK,SAAS;AAC3B,uBAAe;AAAA,MACjB;AAAA,IACF;AAGA,QAAI,aAAa,SAAS,GAAG;AAC3B,aAAO,KAAK;AAAA,QACV,MAAM,aAAa,KAAK,MAAM;AAAA,QAC9B,OAAO,OAAO;AAAA,MAAA,CACf;AAAA,IACH;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKQ,kBAAkB,MAAc,WAAmB,SAA0B;AACnF,UAAM,aAAa,CAAC,QAAQ,MAAM,MAAM,GAAG;AAC3C,WAAO,KAAK,wBAAwB,MAAM,WAAW,SAAS,YAAY,CAAC;AAAA,EAC7E;AAAA,EAEQ,wBACN,MACA,WACA,SACA,YACA,OACS;AAET,UAAM,QAAQ,KAAK,MAAM,KAAK;AAC9B,QAAI,MAAM,UAAU,WAAW;AAC7B,aAAO,CAAC,EAAE,MAAM,OAAO,GAAG;AAAA,IAC5B;AAGA,QAAI,SAAS,WAAW,QAAQ;AAC9B,aAAO,KAAK,kBAAkB,MAAM,WAAW,OAAO;AAAA,IACxD;AAEA,UAAM,YAAY,WAAW,KAAK;AAClC,UAAM,QAAQ,KAAK,MAAM,SAAS;AAElC,UAAM,SAAkB,CAAA;AACxB,QAAI,eAAyB,CAAA;AAC7B,QAAI,cAAc;AAElB,eAAW,QAAQ,OAAO;AACxB,YAAM,YAAY,KAAK,MAAM,KAAK;AAClC,YAAM,WAAW,UAAU;AAE3B,UAAI,cAAc,WAAW,aAAa,aAAa,SAAS,GAAG;AAEjE,cAAM,YAAY,aAAa,KAAK,SAAS;AAC7C,cAAM,YAAY,KAAK;AAAA,UACrB;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA,QAAQ;AAAA,QAAA;AAEV,eAAO,KAAK,GAAG,UAAU,IAAI,CAAC,OAAO,OAAO,EAAE,GAAG,OAAO,OAAO,OAAO,SAAS,EAAA,EAAI,CAAC;AAEpF,uBAAe,CAAC,IAAI;AACpB,sBAAc;AAAA,MAChB,OAAO;AACL,qBAAa,KAAK,IAAI;AACtB,uBAAe;AAAA,MACjB;AAAA,IACF;AAGA,QAAI,aAAa,SAAS,GAAG;AAC3B,YAAM,YAAY,aAAa,KAAK,SAAS;AAC7C,YAAM,YAAY,KAAK;AAAA,QACrB;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA,QAAQ;AAAA,MAAA;AAEV,aAAO,KAAK,GAAG,UAAU,IAAI,CAAC,OAAO,OAAO,EAAE,GAAG,OAAO,OAAO,OAAO,SAAS,EAAA,EAAI,CAAC;AAAA,IACtF;AAEA,WAAO;AAAA,EACT;AACF;AC/IA,MAAM,SAAS,aAAa,EAAE,aAAa,aAAa;AAqBjD,MAAM,kBAAkB,UAAU;AAAA,EAIvC,YACE,QACiB,KACjB;AACA,UAAM,MAAM;AAFK,SAAA,MAAA;AAIjB,UAAM,MAAM,OAAO;AAEnB,SAAK,YAAY;AAAA,MACf,WAAW,KAAK,aAAa;AAAA,MAC7B,eAAe,KAAK,iBAAiB;AAAA,MACrC,WAAW,KAAK,aAAa;AAAA,MAC7B,SAAS,KAAK,WAAW;AAAA,MACzB,gBAAgB,KAAK,kBAAkB;AAAA,MACvC,MAAM,KAAK,QAAQ;AAAA,MACnB,QAAQ,KAAK,UAAU;AAAA,MACvB,aAAa,KAAK,eAAe;AAAA,MACjC,WAAW,KAAK;AAAA,IAAA;AAGlB,SAAK,UAAU,IAAI,QAAA;AAAA,EACrB;AAAA,EAEA,MAAgB,IAAI,SAAoD;AACtE,UAAM,QAAQ,QAAQ;AACtB,UAAM,YAAY,KAAK,UAAU;AAEjC,YAAQ,WAAA;AAAA,MACN,KAAK;AACH,eAAO,MAAM,KAAK,aAAa,KAAsB;AAAA,MACvD,KAAK;AACH,eAAO,MAAM,KAAK,cAAc,KAAuB;AAAA,MACzD;AACE,cAAM,IAAI,MAAM,0BAA0B,SAAS,EAAE;AAAA,IAAA;AAAA,EAE3D;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,aAAa,OAA+C;AACxE,QAAI,CAAC,MAAM,SAAS;AAClB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAEA,QAAI,CAAC,MAAM,IAAI;AACb,YAAM,IAAI,MAAM,wCAAwC;AAAA,IAC1D;AAGA,QAAI,CAAC,KAAK,IAAI,IAAI;AAChB,YAAM,IAAI,MAAM,yEAAyE;AAAA,IAC3F;AAEA,QAAI,CAAC,KAAK,IAAI,WAAW;AACvB,YAAM,IAAI;AAAA,QACR;AAAA,MAAA;AAAA,IAEJ;AAGA,UAAM,SAAS,KAAK,QAAQ;AAAA,MAC1B,MAAM;AAAA,MACN,KAAK,UAAU;AAAA,MACf,KAAK,UAAU;AAAA,MACf,KAAK,UAAU;AAAA,IAAA;AAGjB,WAAO,MAAM,mBAAmB,EAAE,OAAO,MAAM,IAAI,YAAY,OAAO,QAAQ;AAG9E,UAAM,aAAa,MAAM,KAAK,mBAAmB,MAAM;AAGvD,UAAM,KAAK,iBAAiB,MAAM,IAAI,QAAQ,YAAY,MAAM,QAAQ;AAExE,WAAO,KAAK,oBAAoB;AAAA,MAC9B,OAAO,MAAM;AAAA,MACb,QAAQ,OAAO;AAAA,MACf,OAAO,KAAK,UAAU;AAAA,IAAA,CACvB;AAED,WAAO;AAAA,MACL,SAAS,OAAO;AAAA,MAChB,QAAQ,OAAO;AAAA,MACf,gBAAgB,KAAK,UAAU;AAAA,MAC/B,eAAe,KAAK,UAAU;AAAA,IAAA;AAAA,EAElC;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,cAAc,OAAiD;AAC3E,QAAI,CAAC,MAAM,OAAO;AAChB,YAAM,IAAI,MAAM,4CAA4C;AAAA,IAC9D;AAGA,QAAI,CAAC,KAAK,IAAI,IAAI;AAChB,YAAM,IAAI,MAAM,yEAAyE;AAAA,IAC3F;AAEA,QAAI,CAAC,KAAK,IAAI,WAAW;AACvB,YAAM,IAAI;AAAA,QACR;AAAA,MAAA;AAAA,IAEJ;AAGA,UAAM,iBAAiB,MAAM,KAAK,kBAAkB,MAAM,KAAK;AAG/D,QAAI,UAAU,MAAM,KAAK;AAAA,MACvB;AAAA,MACA,MAAM;AAAA,MACN,MAAM,QAAQ,KAAK,UAAU;AAAA,IAAA;AAI/B,UAAM,eAAe,MAAM,UAAU,KAAK,UAAU;AACpD,QAAI,gBAAgB,QAAQ,SAAS,GAAG;AACtC,gBAAU,MAAM,KAAK,OAAO,MAAM,OAAO,OAAO;AAAA,IAClD;AAEA,WAAO,MAAM,oBAAoB;AAAA,MAC/B,OAAO,MAAM,MAAM,MAAM,GAAG,EAAE;AAAA,MAC9B,aAAa,QAAQ;AAAA,MACrB,UAAU;AAAA,IAAA,CACX;AAED,WAAO;AAAA,MACL;AAAA,MACA,OAAO,QAAQ;AAAA,MACf,UAAU;AAAA,IAAA;AAAA,EAEd;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,mBAAmB,QAAsD;AACrF,UAAM,QAAQ,OAAO,IAAI,CAAC,MAAM,EAAE,IAAI;AAGtC,UAAM,YAAY;AAClB,UAAM,gBAA4B,CAAA;AAElC,aAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK,WAAW;AAChD,YAAM,QAAQ,MAAM,MAAM,GAAG,IAAI,SAAS;AAE1C,YAAM,WAAY,MAAM,KAAK,IAAI,GAAG,IAAI,KAAK,UAAU,gBAAiB;AAAA,QACtE,MAAM;AAAA,QACN,SAAS;AAAA;AAAA,MAAA,CACV;AAED,UAAI,CAAC,SAAS,MAAM;AAClB,cAAM,IAAI,MAAM,yDAAyD;AAAA,MAC3E;AAEA,oBAAc,KAAK,GAAG,SAAS,IAAI;AAAA,IACrC;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,kBAAkB,MAAiC;AAC/D,UAAM,WAAY,MAAM,KAAK,IAAI,GAAG,IAAI,KAAK,UAAU,gBAAiB;AAAA,MACtE,MAAM,CAAC,IAAI;AAAA,MACX,SAAS;AAAA,IAAA,CACV;AAED,QAAI,CAAC,SAAS,QAAQ,SAAS,KAAK,WAAW,GAAG;AAChD,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,WAAO,SAAS,KAAK,CAAC;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,iBACZ,OACA,QACA,YACA,UACe;AACf,UAAM,UAAU,OAAO,IAAI,CAAC,OAAO,OAAO;AAAA,MACxC,IAAI,GAAG,KAAK,UAAU,MAAM,KAAK;AAAA,MACjC,QAAQ,WAAW,CAAC;AAAA,MACpB,WAAW,KAAK,UAAU;AAAA,MAC1B,UAAU;AAAA,QACR,SAAS,MAAM;AAAA,QACf;AAAA,QACA,YAAY,MAAM;AAAA,QAClB,GAAG;AAAA,MAAA;AAAA,IACL,EACA;AAGF,UAAM,YAAY;AAClB,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK,WAAW;AAClD,YAAM,QAAQ,QAAQ,MAAM,GAAG,IAAI,SAAS;AAC5C,YAAM,KAAK,IAAI,UAAW,OAAO,KAAK;AAAA,IACxC;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,gBACZ,gBACA,QACA,MACgC;AAChC,UAAM,UAAU,MAAM,KAAK,IAAI,UAAW,MAAM,gBAAgB;AAAA,MAC9D,MAAM,QAAQ,KAAK,UAAU;AAAA,MAC7B,WAAW,KAAK,UAAU;AAAA,MAC1B;AAAA,MACA,cAAc;AAAA;AAAA,MACd,gBAAgB;AAAA;AAAA,IAAA,CACjB;AAGD,WAAO,QAAQ,QAAQ,IAAI,CAAC,WAAW;AAAA,MACrC,IAAI,MAAM;AAAA,MACV,OAAO,MAAM;AAAA,MACb,SAAU,MAAM,UAAU,WAAsB;AAAA,MAChD,UAAU,MAAM,YAAY,CAAA;AAAA,IAAC,EAC7B;AAAA,EACJ;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,OACZ,OACA,SACgC;AAChC,QAAI,QAAQ,WAAW,GAAG;AACxB,aAAO;AAAA,IACT;AAGA,UAAM,WAAW,QAAQ,IAAI,CAAC,OAAO;AAAA,MACnC,MAAM,EAAE;AAAA,IAAA,EACR;AAGF,UAAM,WAAY,MAAM,KAAK,IAAI,GAAG,IAAI,KAAK,UAAU,aAAc;AAAA,MACnE;AAAA,MACA;AAAA,MACA,OAAO,QAAQ;AAAA;AAAA,IAAA,CAChB;AAED,QAAI,CAAC,SAAS,YAAY,SAAS,SAAS,WAAW,GAAG;AACxD,aAAO,KAAK,oDAAoD;AAChE,aAAO;AAAA,IACT;AAGA,UAAM,kBAAyC,CAAA;AAC/C,eAAW,QAAQ,SAAS,UAAU;AACpC,UAAI,KAAK,OAAO,UAAa,KAAK,UAAU,QAAW;AACrD,cAAM,iBAAiB,QAAQ,KAAK,EAAE;AACtC,YAAI,gBAAgB;AAClB,0BAAgB,KAAK;AAAA,YACnB,GAAG;AAAA,YACH,OAAO,KAAK;AAAA;AAAA,UAAA,CACb;AAAA,QACH;AAAA,MACF;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AACF;"}