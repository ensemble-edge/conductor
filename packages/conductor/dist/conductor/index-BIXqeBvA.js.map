{"version":3,"file":"index-BIXqeBvA.js","sources":["../../src/agents/built-in/rag/chunker.ts","../../src/agents/built-in/rag/rag-agent.ts"],"sourcesContent":["/**\n * Text Chunking Strategies\n *\n * Breaks down large text into smaller chunks for embedding\n */\n\nimport type { Chunk, ChunkStrategy } from './types.js'\n\nexport class Chunker {\n  /**\n   * Chunk text based on strategy\n   */\n  chunk(text: string, strategy: ChunkStrategy, chunkSize: number, overlap: number): Chunk[] {\n    switch (strategy) {\n      case 'fixed':\n        return this.fixedSizeChunking(text, chunkSize, overlap)\n      case 'semantic':\n        return this.semanticChunking(text, chunkSize, overlap)\n      case 'recursive':\n        return this.recursiveChunking(text, chunkSize, overlap)\n      default:\n        return this.fixedSizeChunking(text, chunkSize, overlap)\n    }\n  }\n\n  /**\n   * Fixed-size chunking with overlap\n   */\n  private fixedSizeChunking(text: string, chunkSize: number, overlap: number): Chunk[] {\n    const chunks: Chunk[] = []\n    const words = text.split(/\\s+/)\n\n    for (let i = 0; i < words.length; i += chunkSize - overlap) {\n      const chunkWords = words.slice(i, i + chunkSize)\n      const chunkText = chunkWords.join(' ')\n\n      chunks.push({\n        text: chunkText,\n        index: chunks.length,\n      })\n\n      // Stop if we've processed all words\n      if (i + chunkSize >= words.length) {\n        break\n      }\n    }\n\n    return chunks\n  }\n\n  /**\n   * Semantic chunking (breaks on paragraph boundaries)\n   */\n  private semanticChunking(text: string, chunkSize: number, overlap: number): Chunk[] {\n    const chunks: Chunk[] = []\n    const paragraphs = text.split(/\\n\\n+/)\n\n    let currentChunk: string[] = []\n    let currentSize = 0\n\n    for (const paragraph of paragraphs) {\n      const words = paragraph.split(/\\s+/)\n      const paragraphSize = words.length\n\n      // If adding this paragraph would exceed chunk size, save current chunk\n      if (currentSize + paragraphSize > chunkSize && currentChunk.length > 0) {\n        chunks.push({\n          text: currentChunk.join('\\n\\n'),\n          index: chunks.length,\n        })\n\n        // Start new chunk with overlap\n        if (overlap > 0 && currentChunk.length > 0) {\n          const lastParagraph = currentChunk[currentChunk.length - 1]\n          currentChunk = [lastParagraph, paragraph]\n          currentSize = lastParagraph.split(/\\s+/).length + paragraphSize\n        } else {\n          currentChunk = [paragraph]\n          currentSize = paragraphSize\n        }\n      } else {\n        currentChunk.push(paragraph)\n        currentSize += paragraphSize\n      }\n    }\n\n    // Add final chunk\n    if (currentChunk.length > 0) {\n      chunks.push({\n        text: currentChunk.join('\\n\\n'),\n        index: chunks.length,\n      })\n    }\n\n    return chunks\n  }\n\n  /**\n   * Recursive chunking (tries multiple separators)\n   */\n  private recursiveChunking(text: string, chunkSize: number, overlap: number): Chunk[] {\n    const separators = ['\\n\\n', '\\n', '. ', ' ']\n    return this.recursiveChunkingHelper(text, chunkSize, overlap, separators, 0)\n  }\n\n  private recursiveChunkingHelper(\n    text: string,\n    chunkSize: number,\n    overlap: number,\n    separators: string[],\n    depth: number\n  ): Chunk[] {\n    // Base case: if text is small enough, return it as a single chunk\n    const words = text.split(/\\s+/)\n    if (words.length <= chunkSize) {\n      return [{ text, index: 0 }]\n    }\n\n    // If we've run out of separators, fall back to fixed-size chunking\n    if (depth >= separators.length) {\n      return this.fixedSizeChunking(text, chunkSize, overlap)\n    }\n\n    const separator = separators[depth]\n    const parts = text.split(separator)\n\n    const chunks: Chunk[] = []\n    let currentChunk: string[] = []\n    let currentSize = 0\n\n    for (const part of parts) {\n      const partWords = part.split(/\\s+/)\n      const partSize = partWords.length\n\n      if (currentSize + partSize > chunkSize && currentChunk.length > 0) {\n        // Recursively chunk if still too large\n        const chunkText = currentChunk.join(separator)\n        const subChunks = this.recursiveChunkingHelper(\n          chunkText,\n          chunkSize,\n          overlap,\n          separators,\n          depth + 1\n        )\n        chunks.push(...subChunks.map((chunk, i) => ({ ...chunk, index: chunks.length + i })))\n\n        currentChunk = [part]\n        currentSize = partSize\n      } else {\n        currentChunk.push(part)\n        currentSize += partSize\n      }\n    }\n\n    // Process final chunk\n    if (currentChunk.length > 0) {\n      const chunkText = currentChunk.join(separator)\n      const subChunks = this.recursiveChunkingHelper(\n        chunkText,\n        chunkSize,\n        overlap,\n        separators,\n        depth + 1\n      )\n      chunks.push(...subChunks.map((chunk, i) => ({ ...chunk, index: chunks.length + i })))\n    }\n\n    return chunks\n  }\n}\n","/**\n * RAG Agent - Retrieval-Augmented Generation\n *\n * Uses Cloudflare Vectorize and AI embeddings for semantic search\n *\n * Operations:\n * - index: Store content in vector database\n * - search: Find relevant content using semantic search\n */\n\nimport { BaseAgent, type AgentExecutionContext } from '../../base-agent.js'\nimport type { AgentConfig } from '../../../runtime/parser.js'\nimport type {\n  RAGConfig,\n  RAGInput,\n  RAGIndexInput,\n  RAGSearchInput,\n  RAGResult,\n  RAGIndexResult,\n  RAGSearchResult,\n} from './types.js'\nimport { Chunker } from './chunker.js'\n\nexport class RAGMember extends BaseAgent {\n  private ragConfig: RAGConfig\n  private chunker: Chunker\n\n  constructor(\n    config: AgentConfig,\n    private readonly env: Env\n  ) {\n    super(config)\n\n    const cfg = config.config as RAGConfig | undefined\n\n    this.ragConfig = {\n      operation: cfg?.operation || 'search',\n      chunkStrategy: cfg?.chunkStrategy || 'semantic',\n      chunkSize: cfg?.chunkSize || 512,\n      overlap: cfg?.overlap || 50,\n      embeddingModel: cfg?.embeddingModel || '@cf/baai/bge-base-en-v1.5',\n      topK: cfg?.topK || 5,\n      rerank: cfg?.rerank || false,\n      rerankAlgorithm: cfg?.rerankAlgorithm || 'cross-encoder',\n    }\n\n    this.chunker = new Chunker()\n  }\n\n  protected async run(context: AgentExecutionContext): Promise<RAGResult> {\n    const input = context.input as RAGInput\n    const operation = this.ragConfig.operation!\n\n    switch (operation) {\n      case 'index':\n        return await this.indexContent(input as RAGIndexInput)\n      case 'search':\n        return await this.searchContent(input as RAGSearchInput)\n      default:\n        throw new Error(`Unknown RAG operation: ${operation}`)\n    }\n  }\n\n  /**\n   * Index content into vector database\n   */\n  private async indexContent(input: RAGIndexInput): Promise<RAGIndexResult> {\n    if (!input.content) {\n      throw new Error('Index operation requires \"content\" in input')\n    }\n\n    if (!input.id) {\n      throw new Error('Index operation requires \"id\" in input')\n    }\n\n    // 1. Chunk content\n    const chunks = this.chunker.chunk(\n      input.content,\n      this.ragConfig.chunkStrategy!,\n      this.ragConfig.chunkSize!,\n      this.ragConfig.overlap!\n    )\n\n    // 2. Generate embeddings (placeholder - TODO: integrate with CF AI)\n    // For now, we'll just return the count\n    // const embeddings = await this.generateEmbeddings(chunks);\n\n    // 3. Store in Vectorize (placeholder - TODO: integrate with CF Vectorize)\n    // await this.storeInVectorize(input.id, chunks, embeddings, input.metadata);\n\n    return {\n      indexed: chunks.length,\n      chunks: chunks.length,\n      embeddingModel: this.ragConfig.embeddingModel!,\n      chunkStrategy: this.ragConfig.chunkStrategy!,\n    }\n  }\n\n  /**\n   * Search content in vector database\n   */\n  private async searchContent(input: RAGSearchInput): Promise<RAGSearchResult> {\n    if (!input.query) {\n      throw new Error('Search operation requires \"query\" in input')\n    }\n\n    // 1. Generate query embedding (placeholder - TODO: integrate with CF AI)\n    // const queryEmbedding = await this.generateEmbedding(input.query);\n\n    // 2. Search Vectorize (placeholder - TODO: integrate with CF Vectorize)\n    // const results = await this.searchVectorize(queryEmbedding, input.filter);\n\n    // 3. Rerank if configured (placeholder)\n    // if (this.ragConfig.rerank) {\n    //   results = await this.rerank(input.query, results);\n    // }\n\n    // Placeholder response\n    return {\n      results: [],\n      count: 0,\n      reranked: this.ragConfig.rerank!,\n    }\n  }\n\n  /**\n   * Generate embeddings using Cloudflare AI\n   */\n  private async generateEmbeddings(chunks: Array<{ text: string }>): Promise<number[][]> {\n    // TODO: Integrate with Cloudflare AI\n    // const embeddings = await this.env.AI.run(this.ragConfig.embeddingModel!, {\n    //   text: chunks.map(c => c.text)\n    // });\n    // return embeddings.data;\n\n    // Placeholder\n    return chunks.map(() => Array(384).fill(0))\n  }\n\n  /**\n   * Generate a single embedding\n   */\n  private async generateEmbedding(text: string): Promise<number[]> {\n    // TODO: Integrate with Cloudflare AI\n    // const embedding = await this.env.AI.run(this.ragConfig.embeddingModel!, {\n    //   text: [text]\n    // });\n    // return embedding.data[0];\n\n    // Placeholder\n    return Array(384).fill(0)\n  }\n\n  /**\n   * Store chunks in Vectorize\n   */\n  private async storeInVectorize(\n    docId: string,\n    chunks: Array<{ text: string; index: number }>,\n    embeddings: number[][],\n    metadata?: Record<string, unknown>\n  ): Promise<void> {\n    // TODO: Integrate with Cloudflare Vectorize\n    // const vectorize = this.env.VECTORIZE;\n    // await vectorize.upsert(\n    //   chunks.map((chunk, i) => ({\n    //     id: `${docId}-chunk-${chunk.index}`,\n    //     values: embeddings[i],\n    //     metadata: {\n    //       content: chunk.text,\n    //       docId,\n    //       chunkIndex: chunk.index,\n    //       ...metadata\n    //     }\n    //   }))\n    // );\n  }\n\n  /**\n   * Search Vectorize for similar vectors\n   */\n  private async searchVectorize(\n    queryEmbedding: number[],\n    filter?: Record<string, unknown>\n  ): Promise<Array<{ score: number; metadata: Record<string, unknown> }>> {\n    // TODO: Integrate with Cloudflare Vectorize\n    // const vectorize = this.env.VECTORIZE;\n    // const results = await vectorize.query(queryEmbedding, {\n    //   topK: this.ragConfig.topK!,\n    //   filter,\n    //   returnValues: true,\n    //   returnMetadata: true\n    // });\n    // return results.matches;\n\n    // Placeholder\n    return []\n  }\n\n  /**\n   * Rerank search results\n   */\n  private async rerank(\n    query: string,\n    results: Array<{ score: number; metadata: Record<string, unknown> }>\n  ): Promise<Array<{ score: number; metadata: Record<string, unknown> }>> {\n    // TODO: Implement reranking algorithms\n    // - cross-encoder: Use a cross-encoder model for reranking\n    // - mmr: Maximal Marginal Relevance for diversity\n\n    // For now, just return results as-is\n    return results\n  }\n}\n"],"names":[],"mappings":";AAQO,MAAM,QAAQ;AAAA;AAAA;AAAA;AAAA,EAInB,MAAM,MAAc,UAAyB,WAAmB,SAA0B;AACxF,YAAQ,UAAA;AAAA,MACN,KAAK;AACH,eAAO,KAAK,kBAAkB,MAAM,WAAW,OAAO;AAAA,MACxD,KAAK;AACH,eAAO,KAAK,iBAAiB,MAAM,WAAW,OAAO;AAAA,MACvD,KAAK;AACH,eAAO,KAAK,kBAAkB,MAAM,WAAW,OAAO;AAAA,MACxD;AACE,eAAO,KAAK,kBAAkB,MAAM,WAAW,OAAO;AAAA,IAAA;AAAA,EAE5D;AAAA;AAAA;AAAA;AAAA,EAKQ,kBAAkB,MAAc,WAAmB,SAA0B;AACnF,UAAM,SAAkB,CAAA;AACxB,UAAM,QAAQ,KAAK,MAAM,KAAK;AAE9B,aAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK,YAAY,SAAS;AAC1D,YAAM,aAAa,MAAM,MAAM,GAAG,IAAI,SAAS;AAC/C,YAAM,YAAY,WAAW,KAAK,GAAG;AAErC,aAAO,KAAK;AAAA,QACV,MAAM;AAAA,QACN,OAAO,OAAO;AAAA,MAAA,CACf;AAGD,UAAI,IAAI,aAAa,MAAM,QAAQ;AACjC;AAAA,MACF;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKQ,iBAAiB,MAAc,WAAmB,SAA0B;AAClF,UAAM,SAAkB,CAAA;AACxB,UAAM,aAAa,KAAK,MAAM,OAAO;AAErC,QAAI,eAAyB,CAAA;AAC7B,QAAI,cAAc;AAElB,eAAW,aAAa,YAAY;AAClC,YAAM,QAAQ,UAAU,MAAM,KAAK;AACnC,YAAM,gBAAgB,MAAM;AAG5B,UAAI,cAAc,gBAAgB,aAAa,aAAa,SAAS,GAAG;AACtE,eAAO,KAAK;AAAA,UACV,MAAM,aAAa,KAAK,MAAM;AAAA,UAC9B,OAAO,OAAO;AAAA,QAAA,CACf;AAGD,YAAI,UAAU,KAAK,aAAa,SAAS,GAAG;AAC1C,gBAAM,gBAAgB,aAAa,aAAa,SAAS,CAAC;AAC1D,yBAAe,CAAC,eAAe,SAAS;AACxC,wBAAc,cAAc,MAAM,KAAK,EAAE,SAAS;AAAA,QACpD,OAAO;AACL,yBAAe,CAAC,SAAS;AACzB,wBAAc;AAAA,QAChB;AAAA,MACF,OAAO;AACL,qBAAa,KAAK,SAAS;AAC3B,uBAAe;AAAA,MACjB;AAAA,IACF;AAGA,QAAI,aAAa,SAAS,GAAG;AAC3B,aAAO,KAAK;AAAA,QACV,MAAM,aAAa,KAAK,MAAM;AAAA,QAC9B,OAAO,OAAO;AAAA,MAAA,CACf;AAAA,IACH;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKQ,kBAAkB,MAAc,WAAmB,SAA0B;AACnF,UAAM,aAAa,CAAC,QAAQ,MAAM,MAAM,GAAG;AAC3C,WAAO,KAAK,wBAAwB,MAAM,WAAW,SAAS,YAAY,CAAC;AAAA,EAC7E;AAAA,EAEQ,wBACN,MACA,WACA,SACA,YACA,OACS;AAET,UAAM,QAAQ,KAAK,MAAM,KAAK;AAC9B,QAAI,MAAM,UAAU,WAAW;AAC7B,aAAO,CAAC,EAAE,MAAM,OAAO,GAAG;AAAA,IAC5B;AAGA,QAAI,SAAS,WAAW,QAAQ;AAC9B,aAAO,KAAK,kBAAkB,MAAM,WAAW,OAAO;AAAA,IACxD;AAEA,UAAM,YAAY,WAAW,KAAK;AAClC,UAAM,QAAQ,KAAK,MAAM,SAAS;AAElC,UAAM,SAAkB,CAAA;AACxB,QAAI,eAAyB,CAAA;AAC7B,QAAI,cAAc;AAElB,eAAW,QAAQ,OAAO;AACxB,YAAM,YAAY,KAAK,MAAM,KAAK;AAClC,YAAM,WAAW,UAAU;AAE3B,UAAI,cAAc,WAAW,aAAa,aAAa,SAAS,GAAG;AAEjE,cAAM,YAAY,aAAa,KAAK,SAAS;AAC7C,cAAM,YAAY,KAAK;AAAA,UACrB;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA,QAAQ;AAAA,QAAA;AAEV,eAAO,KAAK,GAAG,UAAU,IAAI,CAAC,OAAO,OAAO,EAAE,GAAG,OAAO,OAAO,OAAO,SAAS,EAAA,EAAI,CAAC;AAEpF,uBAAe,CAAC,IAAI;AACpB,sBAAc;AAAA,MAChB,OAAO;AACL,qBAAa,KAAK,IAAI;AACtB,uBAAe;AAAA,MACjB;AAAA,IACF;AAGA,QAAI,aAAa,SAAS,GAAG;AAC3B,YAAM,YAAY,aAAa,KAAK,SAAS;AAC7C,YAAM,YAAY,KAAK;AAAA,QACrB;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA,QAAQ;AAAA,MAAA;AAEV,aAAO,KAAK,GAAG,UAAU,IAAI,CAAC,OAAO,OAAO,EAAE,GAAG,OAAO,OAAO,OAAO,SAAS,EAAA,EAAI,CAAC;AAAA,IACtF;AAEA,WAAO;AAAA,EACT;AACF;AClJO,MAAM,kBAAkB,UAAU;AAAA,EAIvC,YACE,QACiB,KACjB;AACA,UAAM,MAAM;AAFK,SAAA,MAAA;AAIjB,UAAM,MAAM,OAAO;AAEnB,SAAK,YAAY;AAAA,MACf,WAAW,KAAK,aAAa;AAAA,MAC7B,eAAe,KAAK,iBAAiB;AAAA,MACrC,WAAW,KAAK,aAAa;AAAA,MAC7B,SAAS,KAAK,WAAW;AAAA,MACzB,gBAAgB,KAAK,kBAAkB;AAAA,MACvC,MAAM,KAAK,QAAQ;AAAA,MACnB,QAAQ,KAAK,UAAU;AAAA,MACvB,iBAAiB,KAAK,mBAAmB;AAAA,IAAA;AAG3C,SAAK,UAAU,IAAI,QAAA;AAAA,EACrB;AAAA,EAEA,MAAgB,IAAI,SAAoD;AACtE,UAAM,QAAQ,QAAQ;AACtB,UAAM,YAAY,KAAK,UAAU;AAEjC,YAAQ,WAAA;AAAA,MACN,KAAK;AACH,eAAO,MAAM,KAAK,aAAa,KAAsB;AAAA,MACvD,KAAK;AACH,eAAO,MAAM,KAAK,cAAc,KAAuB;AAAA,MACzD;AACE,cAAM,IAAI,MAAM,0BAA0B,SAAS,EAAE;AAAA,IAAA;AAAA,EAE3D;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,aAAa,OAA+C;AACxE,QAAI,CAAC,MAAM,SAAS;AAClB,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC/D;AAEA,QAAI,CAAC,MAAM,IAAI;AACb,YAAM,IAAI,MAAM,wCAAwC;AAAA,IAC1D;AAGA,UAAM,SAAS,KAAK,QAAQ;AAAA,MAC1B,MAAM;AAAA,MACN,KAAK,UAAU;AAAA,MACf,KAAK,UAAU;AAAA,MACf,KAAK,UAAU;AAAA,IAAA;AAUjB,WAAO;AAAA,MACL,SAAS,OAAO;AAAA,MAChB,QAAQ,OAAO;AAAA,MACf,gBAAgB,KAAK,UAAU;AAAA,MAC/B,eAAe,KAAK,UAAU;AAAA,IAAA;AAAA,EAElC;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,cAAc,OAAiD;AAC3E,QAAI,CAAC,MAAM,OAAO;AAChB,YAAM,IAAI,MAAM,4CAA4C;AAAA,IAC9D;AAcA,WAAO;AAAA,MACL,SAAS,CAAA;AAAA,MACT,OAAO;AAAA,MACP,UAAU,KAAK,UAAU;AAAA,IAAA;AAAA,EAE7B;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,mBAAmB,QAAsD;AAQrF,WAAO,OAAO,IAAI,MAAM,MAAM,GAAG,EAAE,KAAK,CAAC,CAAC;AAAA,EAC5C;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,kBAAkB,MAAiC;AAQ/D,WAAO,MAAM,GAAG,EAAE,KAAK,CAAC;AAAA,EAC1B;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,iBACZ,OACA,QACA,YACA,UACe;AAAA,EAejB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,gBACZ,gBACA,QACsE;AAYtE,WAAO,CAAA;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,OACZ,OACA,SACsE;AAMtE,WAAO;AAAA,EACT;AACF;"}