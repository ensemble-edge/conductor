name: robots
type: Page
templateEngine: liquid
description: Robots.txt for search engine crawlers

# The component content (must be at root level, not nested in config)
component: |
  User-agent: *
  {% if disallowAll %}
  Disallow: /
  {% else %}
  Allow: /
  {% if disallowPaths %}
  {% for path in disallowPaths %}
  Disallow: {{path}}
  {% endfor %}
  {% endif %}
  {% endif %}

  {% if crawlDelay %}
  Crawl-delay: {{crawlDelay}}
  {% endif %}

  {% if sitemap %}
  Sitemap: {{sitemap}}
  {% endif %}

# Page configuration (all properties at root level, no config wrapper)
route:
  path: /robots.txt
  methods: [GET]
  auth: none

renderMode: static

# Return plain text, not HTML
contentType: text/plain

cache:
  enabled: true
  ttl: 86400  # 24 hours

# Default configuration
input:
  disallowAll: false
  disallowPaths:
    - /api/*
    - /admin/*
    - /_*
  crawlDelay: null
  sitemap: ${env.PUBLIC_URL}/sitemap.xml
